{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef60fbd0",
   "metadata": {},
   "source": [
    "### Notebook sur le jeu de test du Titanic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e095d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "trainDataSetPath = os.path.join(\"datasets\",\"titanic\",\"train.csv\")\n",
    "testDataSetPath = os.path.join(\"datasets\",\"titanic\",\"test.csv\")\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3a5d79b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainDf = pd.read_csv(trainDataSetPath)\n",
    "trainDf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9dc106db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "trainDf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9d2f3e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  Gender\n",
       "0         0       3    0  22.0      1      0   7.2500         0       0\n",
       "1         1       1    1  38.0      1      0  71.2833         1       1\n",
       "2         1       3    1  26.0      0      0   7.9250         0       1\n",
       "3         1       1    1  35.0      1      0  53.1000         0       1\n",
       "4         0       3    0  35.0      0      0   8.0500         0       0\n",
       "5         0       3    0  28.0      0      0   8.4583         2       0\n",
       "6         0       1    0  54.0      0      0  51.8625         0       0\n",
       "7         0       3    0   2.0      3      1  21.0750         0       0\n",
       "8         1       3    1  27.0      0      2  11.1333         0       1\n",
       "9         1       2    1  14.0      1      0  30.0708         1       1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from titanic.normalize import normalize \n",
    "trainDf = normalize.normalize(trainDf)\n",
    "trainDf.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d1a186eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    1.000000\n",
       "Sex         0.543351\n",
       "Gender      0.543351\n",
       "Fare        0.257307\n",
       "Embarked    0.106811\n",
       "Parch       0.081629\n",
       "SibSp      -0.035322\n",
       "Age        -0.064910\n",
       "Pclass     -0.338481\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = trainDf.corr()\n",
    "corr_matrix['Survived'] .sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec404de5",
   "metadata": {},
   "source": [
    "#### Créer un jeu de test et un jeu d'entrainement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f0033177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit \n",
    "\n",
    "split = ShuffleSplit(n_splits=1, test_size=0.2,random_state=42) \n",
    "for train_index, test_index in split.split(trainDf,trainDf['Fare']):\n",
    "    trainSet = trainDf.loc[train_index] \n",
    "    testSet = trainDf.loc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273601af",
   "metadata": {},
   "source": [
    "#### On calcule les prédictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db69dd21",
   "metadata": {},
   "source": [
    "###  On va utiliser un DecisionTreeClassifier \n",
    "####  Recherche des meilleurs paramétres par quadrillage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9b250158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 2,\n",
       " 'min_samples_split': 50,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "param_grid = [{ \n",
    "    'criterion' : [ 'gini', 'entropy', 'log_loss' ] , \n",
    "    'splitter'  : [ 'best', 'random' ] , \n",
    "    'max_depth' : [2,3,4] , \n",
    "    \"min_samples_split\" : [50 , 25 , 10 ]}\n",
    "]\n",
    "dcl = DecisionTreeClassifier()\n",
    "gridSearch = GridSearchCV(dcl , param_grid,cv=5,scoring='neg_mean_squared_error',return_train_score=True )\n",
    "target  = trainSet['Survived'] \n",
    "gridSearch.fit(trainSet,target )\n",
    "gridSearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "81374809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=2, min_samples_split=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=2, min_samples_split=50)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2, min_samples_split=50)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "dcl = DecisionTreeClassifier(criterion = 'gini',\n",
    "                             max_depth= 2,\n",
    "                             min_samples_split = 50,\n",
    "                             splitter='best') \n",
    "dcl.fit(trainSet,target)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419ea4ca",
   "metadata": {},
   "source": [
    "### Evaluation des predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e7274469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1\n",
      " 0 0 0 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1\n",
      " 0 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed = testSet[\"Survived\"]\n",
    "observed = observed.to_numpy(dtype='int64', copy=True) \n",
    "predictions = dcl.predict(testSet)\n",
    "print(observed)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ace72988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nb Erreurs pour la classe DecisionTreeClassifier: 0 (0.00%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluateResult(predictions):\n",
    "    nbErrors = 0 \n",
    "    for i in range(0,len(predictions)):\n",
    "        if predictions[i] != observed[i]:\n",
    "            nbErrors += 1\n",
    "    ratio = (nbErrors / len(predictions) ) * 100 \n",
    "    return nbErrors, ratio \n",
    "\n",
    "nbErrors , ratio = evaluateResult(predictions)  \n",
    "print(f' nb Erreurs pour la classe {dcl.__class__.__name__}: {nbErrors} ({ratio:4.2f}%)')    \n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d0e864",
   "metadata": {},
   "source": [
    "### Test d'un SGDClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d286fb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nb Erreurs pour la classe SGDClassifier: 34 (18.99%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier \n",
    "sgdClf = SGDClassifier(random_state=42) \n",
    "# entraînement \n",
    "sgdClf.fit(trainSetClean,target)\n",
    "predictions = sgdClf.predict(testSet2)\n",
    "nbErrors , ratio = evaluateResult(predictions)  \n",
    "print(f' nb Erreurs pour la classe {sgdClf.__class__.__name__}: {nbErrors} ({ratio:4.2f}%)')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "927d9708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nb Erreurs pour la classe SGDRegressor: 179 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor \n",
    "sgdReg = SGDRegressor(max_iter=1000, tol=1e-3,penalty=None,eta0=0.1) \n",
    "# entraînement \n",
    "sgdReg.fit(trainSetClean,target.ravel())\n",
    "predictions = sgdReg.predict(testSet2)\n",
    "nbErrors , ratio = evaluateResult(predictions)  \n",
    "print(f' nb Erreurs pour la classe {sgdReg.__class__.__name__}: {nbErrors} ({ratio:4.2f}%)')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1b7aa324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nb Erreurs pour la classe ElasticNet: 179 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet \n",
    "enReg = ElasticNet(alpha=0.1, l1_ratio=0.5) \n",
    "# entraînement \n",
    "enReg.fit(trainSetClean,target.ravel())\n",
    "predictions = enReg.predict(testSet2)\n",
    "nbErrors , ratio = evaluateResult(predictions)  \n",
    "print(f' nb Erreurs pour la classe {enReg.__class__.__name__}: {nbErrors} ({ratio:4.2f}%)')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0a92e0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nb Erreurs pour la classe LinearSVC: 39 (21.79%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC \n",
    "svmLinear = LinearSVC(C=1, loss=\"hinge\",dual=\"auto\",max_iter=10**6) \n",
    "# entraînement \n",
    "svmLinear.fit(trainSetClean,target)\n",
    "predictions = svmLinear.predict(testSet2)\n",
    "nbErrors , ratio = evaluateResult(predictions)  \n",
    "print(f' nb Erreurs pour la classe {svmLinear.__class__.__name__}: {nbErrors} ({ratio:4.2f}%)') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a87ecafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.5, 'dual': True, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'random_state': 42, 'tol': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "240 fits failed out of a total of 480.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py\", line 315, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "                                           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1221, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1060, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py\", line 315, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "                                           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1221, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1060, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py\", line 315, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "                                           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1221, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1060, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py\", line 315, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "                                           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1221, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1060, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan  0.         0.         0.\n",
      "        nan        nan        nan  0.         0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "  0.         0.         0.        -0.0028169  0.         0.\n",
      "        nan        nan        nan  0.         0.         0.\n",
      "        nan        nan        nan  0.         0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "  0.         0.         0.        -0.0028169  0.         0.\n",
      "        nan        nan        nan  0.         0.         0.\n",
      "        nan        nan        nan  0.         0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "  0.         0.         0.        -0.0028169  0.         0.\n",
      "        nan        nan        nan  0.         0.         0.\n",
      "        nan        nan        nan  0.         0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "  0.         0.         0.        -0.0028169  0.         0.       ]\n",
      "  warnings.warn(\n",
      "C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the train scores are non-finite: [        nan         nan         nan  0.          0.          0.\n",
      "         nan         nan         nan  0.          0.          0.\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "  0.          0.          0.         -0.00070299  0.          0.\n",
      "         nan         nan         nan  0.          0.          0.\n",
      "         nan         nan         nan  0.          0.          0.\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "  0.          0.          0.         -0.00070299  0.          0.\n",
      "         nan         nan         nan  0.          0.          0.\n",
      "         nan         nan         nan  0.          0.          0.\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "  0.          0.          0.         -0.00070299  0.          0.\n",
      "         nan         nan         nan  0.          0.          0.\n",
      "         nan         nan         nan  0.          0.          0.\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "  0.          0.          0.         -0.00070299  0.          0.        ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def gridsearchcv(model):\n",
    "\n",
    "    param_grid = [{ \n",
    "        'penalty' : [ 'l1', 'l2' ] , \n",
    "        'loss'  : [ 'hinge', 'squared_hinge' ] , \n",
    "        'dual' : [True,False] , \n",
    "        \"tol\" : [10 ** -n for n in range(1,4) ] , \n",
    "        \"C\" : [0.5,1,1.5,2],\n",
    "        \"random_state\" : [42] , \n",
    "        \"max_iter\" : [ 10 ** 6   ]}\n",
    "    ]\n",
    "\n",
    "    gridSearch = GridSearchCV(model , param_grid,cv=5,scoring='neg_mean_squared_error',return_train_score=True )\n",
    "    target  = trainSet['Survived'] \n",
    "    gridSearch.fit(trainSet,target )\n",
    "    return gridSearch.best_params_\n",
    "\n",
    "lSVC = LinearSVC()\n",
    "bp = gridsearchcv(lSVC)\n",
    "print(bp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65efc9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e460e91",
   "metadata": {},
   "source": [
    "### Test de LinearSVC mais en utilisant un StandardScaler sur les données en entrée "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a1a9ae78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1\n",
      " 0 0 0 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1\n",
      " 0 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "sc = StandardScaler()\n",
    "svmLinear = LinearSVC(C=0.5, dual = True, \n",
    "                      loss= 'squared_hinge', \n",
    "                       max_iter = 1000000, \n",
    "                       penalty = 'l2', \n",
    "                       random_state = 42, \n",
    "                       tol = 0.01 ) \n",
    "# entraînement \n",
    "trainSetCleanSc = sc.fit_transform(trainSetClean)\n",
    "svmLinear.fit(trainSetCleanSc,target)\n",
    "testSetSc = sc.fit_transform(testSet2)\n",
    "predictions = svmLinear.predict(testSetSc)\n",
    "print(observed)\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dd83e33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nb Erreurs pour la classe LinearSVC: 37 (20.67%)\n"
     ]
    }
   ],
   "source": [
    "nbErrors , ratio = evaluateResult(predictions)  \n",
    "print(f' nb Erreurs pour la classe {svmLinear.__class__.__name__}: {nbErrors} ({ratio:4.2f}%)') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d13a730",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
