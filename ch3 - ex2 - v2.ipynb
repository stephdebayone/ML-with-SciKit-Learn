{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef60fbd0",
   "metadata": {},
   "source": [
    "### Notebook sur le jeu de test du Titanic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e095d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "trainDataSetPath = os.path.join(\"datasets\",\"titanic\",\"train.csv\")\n",
    "testDataSetPath = os.path.join(\"datasets\",\"titanic\",\"test.csv\")\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a5d79b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDf = pd.read_csv(trainDataSetPath)\n",
    "dataDf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dc106db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "dataDf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b3b0cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stallard\\AppData\\Local\\Temp\\ipykernel_14592\\1610635063.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  corr_matrix = dataDf.corr()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Survived       1.000000\n",
       "Fare           0.257307\n",
       "Parch          0.081629\n",
       "PassengerId   -0.005007\n",
       "SibSp         -0.035322\n",
       "Age           -0.077221\n",
       "Pclass        -0.338481\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = dataDf.corr()\n",
    "corr_matrix['Survived'] .sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d2f3e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       "0         0       3    0  22.0      1      0   7.2500         0\n",
       "1         1       1    1  38.0      1      0  71.2833         1\n",
       "2         1       3    1  26.0      0      0   7.9250         0\n",
       "3         1       1    1  35.0      1      0  53.1000         0\n",
       "4         0       3    0  35.0      0      0   8.0500         0\n",
       "5         0       3    0  28.0      0      0   8.4583         2\n",
       "6         0       1    0  54.0      0      0  51.8625         0\n",
       "7         0       3    0   2.0      3      1  21.0750         0\n",
       "8         1       3    1  27.0      0      2  11.1333         0\n",
       "9         1       2    1  14.0      1      0  30.0708         1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from titanic.normalize import normalize \n",
    "nmDataDf = normalize.normalize(dataDf)\n",
    "nmDataDf.head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec404de5",
   "metadata": {},
   "source": [
    "#### Créer un jeu de test et un jeu d'entrainement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0033177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit \n",
    "\n",
    "split = ShuffleSplit(n_splits=1, test_size=0.2,random_state=42) \n",
    "for train_index, test_index in split.split(nmDataDf,nmDataDf['Fare']):\n",
    "    # set d'entrainement \n",
    "    trainSet = nmDataDf.loc[train_index]\n",
    "    # set de test \n",
    "    testSet = nmDataDf.loc[test_index]\n",
    "\n",
    "# résultats attendus \n",
    "target = trainSet['Survived']\n",
    "# on enlève la colonne Survived car on ne veut pas apprendre sur cette colonne \n",
    "trainSet = trainSet.drop(columns=['Survived'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273601af",
   "metadata": {},
   "source": [
    "#### On calcule les prédictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db69dd21",
   "metadata": {},
   "source": [
    "###  On va utiliser un DecisionTreeClassifier \n",
    "####  Recherche des meilleurs paramétres par quadrillage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b250158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 3,\n",
       " 'min_samples_split': 10,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "param_grid = [{ \n",
    "    'criterion' : [ 'gini', 'entropy', 'log_loss' ] , \n",
    "    'splitter'  : [ 'best', 'random' ] , \n",
    "    'max_depth' : [2,3,4] , \n",
    "    \"min_samples_split\" : [50 , 25 , 10 ]}\n",
    "]\n",
    "dcl = DecisionTreeClassifier()\n",
    "gridSearch = GridSearchCV(dcl , param_grid,cv=5,scoring='neg_mean_squared_error',return_train_score=True )\n",
    "\n",
    "gridSearch.fit(trainSet,target )\n",
    "\n",
    "gridSearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81374809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3, min_samples_split=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3, min_samples_split=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=3, min_samples_split=10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "dcl = DecisionTreeClassifier(criterion = 'entropy',\n",
    "                             max_depth= 3,\n",
    "                             min_samples_split = 10,\n",
    "                             splitter='best') \n",
    "dcl.fit(trainSet,target)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419ea4ca",
   "metadata": {},
   "source": [
    "### Evaluation des predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7274469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1\n",
      " 0 0 0 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1\n",
      " 0 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed = testSet[\"Survived\"]\n",
    "observed = observed.to_numpy(dtype='int64', copy=True) \n",
    "testSet = testSet.drop(columns=['Survived'])\n",
    "predictions = dcl.predict(testSet)\n",
    "print(observed)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ace72988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nb Erreurs pour la classe DecisionTreeClassifier: 36 (20.11%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluateResult(predictions):\n",
    "    nbErrors = 0 \n",
    "    for i in range(0,len(predictions)):\n",
    "        if predictions[i] != observed[i]:\n",
    "            nbErrors += 1\n",
    "    ratio = (nbErrors / len(predictions) ) * 100 \n",
    "    return nbErrors, ratio \n",
    "\n",
    "nbErrors , ratio = evaluateResult(predictions)  \n",
    "print(f' nb Erreurs pour la classe {dcl.__class__.__name__}: {nbErrors} ({ratio:4.2f}%)')    \n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d0e864",
   "metadata": {},
   "source": [
    "### Test d'un SGDClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d286fb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nb Erreurs pour la classe SGDClassifier: 39 (21.79%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier \n",
    "sgdClf = SGDClassifier(random_state=42) \n",
    "# entraînement \n",
    "sgdClf.fit(trainSet,target)\n",
    "predictions = sgdClf.predict(testSet)\n",
    "nbErrors , ratio = evaluateResult(predictions)  \n",
    "print(f' nb Erreurs pour la classe {sgdClf.__class__.__name__}: {nbErrors} ({ratio:4.2f}%)')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "927d9708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nb Erreurs pour la classe SGDRegressor: 179 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor \n",
    "sgdReg = SGDRegressor(max_iter=1000, tol=1e-3,penalty=None,eta0=0.1) \n",
    "# entraînement \n",
    "sgdReg.fit(trainSet,target)\n",
    "predictions = sgdReg.predict(testSet)\n",
    "nbErrors , ratio = evaluateResult(predictions)  \n",
    "print(f' nb Erreurs pour la classe {sgdReg.__class__.__name__}: {nbErrors} ({ratio:4.2f}%)')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b7aa324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nb Erreurs pour la classe ElasticNet: 179 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet \n",
    "enReg = ElasticNet(alpha=0.1, l1_ratio=0.5) \n",
    "# entraînement \n",
    "enReg.fit(trainSet,target)\n",
    "predictions = enReg.predict(testSet)\n",
    "nbErrors , ratio = evaluateResult(predictions)  \n",
    "print(f' nb Erreurs pour la classe {enReg.__class__.__name__}: {nbErrors} ({ratio:4.2f}%)')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a92e0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nb Erreurs pour la classe LinearSVC: 39 (21.79%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC \n",
    "svmLinear = LinearSVC(C=1, loss=\"hinge\",dual=\"auto\",max_iter=10**6) \n",
    "# entraînement \n",
    "svmLinear.fit(trainSet,target)\n",
    "predictions = svmLinear.predict(testSet)\n",
    "nbErrors , ratio = evaluateResult(predictions)  \n",
    "print(f' nb Erreurs pour la classe {svmLinear.__class__.__name__}: {nbErrors} ({ratio:4.2f}%)') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a87ecafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "60 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py\", line 315, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "                                           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1221, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1060, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [-0.21211465 -0.2107062  -0.21211465         nan         nan         nan\n",
      " -0.21211465 -0.21211465 -0.2135231          nan         nan         nan\n",
      " -0.21211465 -0.2135231  -0.2135231          nan         nan         nan\n",
      " -0.2135231  -0.2121245  -0.2135231          nan         nan         nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\stallard\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the train scores are non-finite: [-0.20681466 -0.20681466 -0.20646379         nan         nan         nan\n",
      " -0.20716554 -0.20646379 -0.20365554         nan         nan         nan\n",
      " -0.20646379 -0.20540992 -0.20435729         nan         nan         nan\n",
      " -0.20611291 -0.20470755 -0.20576327         nan         nan         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.5, 'dual': True, 'loss': 'hinge', 'max_iter': 1000000, 'penalty': 'l2', 'random_state': 42, 'tol': 0.01}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def gridsearchcv(model, itrainSet, itarget):\n",
    "\n",
    "    param_grid = [{ \n",
    "        'penalty' : [ 'l2' ] , \n",
    "        'loss'  : [ 'hinge' ] , # 'squared_hinge' \n",
    "        'dual' : [True,False] , \n",
    "        \"tol\" : [10 ** -n for n in range(1,4) ] , \n",
    "        \"C\" : [0.5,1,1.5,2],\n",
    "        \"random_state\" : [42] , \n",
    "        \"max_iter\" : [ 10 ** 6   ]}\n",
    "    ]\n",
    "\n",
    "    gridSearch = GridSearchCV(model , param_grid,cv=5,scoring='neg_mean_squared_error',return_train_score=True )\n",
    "    gridSearch.fit(itrainSet,itarget )\n",
    "    return gridSearch.best_params_\n",
    "\n",
    "lSVC = LinearSVC()\n",
    "bp = gridsearchcv(lSVC,trainSet,target)\n",
    "print(bp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65efc9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e460e91",
   "metadata": {},
   "source": [
    "### Test de LinearSVC mais en utilisant un StandardScaler sur les données en entrée "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1a9ae78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1\n",
      " 0 0 0 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1\n",
      " 0 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "sc = StandardScaler()\n",
    "svmLinear = LinearSVC(C=0.5, dual = True, \n",
    "                      loss= 'hinge', \n",
    "                       max_iter = 1000000, \n",
    "                       penalty = 'l2', \n",
    "                       random_state = 42, \n",
    "                       tol = 0.01 ) \n",
    "# entraînement \n",
    "# trainSetCleanSc = sc.fit_transform(trainSetClean)\n",
    "svmLinear.fit(trainSet,target)\n",
    "predictions = svmLinear.predict(testSet)\n",
    "print(observed)\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd83e33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nb Erreurs pour la classe LinearSVC: 39 (21.79%)\n"
     ]
    }
   ],
   "source": [
    "nbErrors , ratio = evaluateResult(predictions)  \n",
    "print(f' nb Erreurs pour la classe {svmLinear.__class__.__name__}: {nbErrors} ({ratio:4.2f}%)') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d13a730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1\n",
      " 0 0 0 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1\n",
      " 0 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 8.78593960e-02,  2.49411501e-01,  1.45326201e-01,  8.67059895e-01,\n",
       "        6.83112118e-01,  9.69348651e-01,  6.92254009e-01,  8.94474386e-02,\n",
       "        7.47964976e-01,  9.37293981e-01,  3.55361468e-01,  3.39609875e-02,\n",
       "        4.88988264e-01,  1.34794794e-01,  2.27333025e-01,  9.77523449e-01,\n",
       "        3.31900897e-01,  6.92289948e-01,  2.69116251e-01,  3.47946927e-01,\n",
       "        1.26742628e-01,  3.96752008e-01,  6.22150028e-01,  1.45916103e-01,\n",
       "        1.11169099e-01,  4.15853386e-02,  4.05639838e-01,  2.50545928e-01,\n",
       "        6.94408223e-02,  6.05949473e-01,  1.49955531e-01,  6.47685416e-01,\n",
       "        4.62700773e-01,  6.19739178e-01,  1.54668083e-01,  1.12492522e-01,\n",
       "        4.28668740e-01,  6.92254009e-01,  9.65277435e-01,  1.08172306e-01,\n",
       "        2.45404041e-01,  6.36336074e-02,  1.08242277e-01,  1.80530223e-01,\n",
       "        5.59810519e-01,  7.53390952e-02,  1.50074646e-01,  1.31988361e-01,\n",
       "        1.26358829e-01,  3.20195881e-01,  6.68672879e-01,  7.95429134e-01,\n",
       "       -5.93707562e-02,  4.65726327e-01,  8.75474027e-03,  9.66152811e-01,\n",
       "        2.44768921e-01,  9.50326885e-01,  7.47329558e-01,  7.34095862e-01,\n",
       "        1.40615555e-01,  8.28435925e-01,  7.42586064e-01,  4.24323885e-01,\n",
       "        1.80530223e-01,  6.40428192e-01,  3.24424867e-01,  1.03520287e-01,\n",
       "        1.35290084e-01,  8.45078496e-01,  7.31521474e-01,  1.00625929e+00,\n",
       "        4.71670201e-01,  8.87301959e-01,  1.31366332e-01,  3.49945006e-02,\n",
       "        6.80647558e-01,  9.70113338e-01,  7.29771650e-01,  5.24432001e-01,\n",
       "       -8.19837673e-05,  7.70420449e-01,  9.05956741e-01,  1.80524551e-01,\n",
       "        3.32708516e-01,  2.71604509e-01,  9.58458433e-01,  9.77043349e-01,\n",
       "        3.66134072e-01,  1.07879261e-01,  1.61412598e-01,  5.19972769e-01,\n",
       "        2.74020952e-01,  1.80520784e-01,  1.08172306e-01,  1.08153429e-01,\n",
       "        3.03793933e-01,  2.93184068e-02,  7.39056811e-01,  1.12814886e-01,\n",
       "        2.57225016e-01,  7.53244750e-02,  1.00409759e+00,  6.13627003e-02,\n",
       "        9.66358257e-02,  8.25348195e-02,  6.72424366e-01,  3.41821021e-01,\n",
       "        9.96150837e-02,  4.07127843e-01,  9.08369332e-01,  1.42698615e-01,\n",
       "        9.61418172e-01,  3.87347732e-01,  5.13196798e-01,  1.46197804e-01,\n",
       "        2.64866013e-01,  2.63488342e-01,  7.51453109e-01,  4.38500302e-01,\n",
       "        1.87635341e-01,  9.76544324e-01,  7.57658128e-01,  3.57173416e-01,\n",
       "        1.21807002e-01,  4.28321466e-01,  8.38555384e-01,  5.03280884e-01,\n",
       "        6.19575588e-01,  1.40740342e-01,  6.92312636e-01,  8.78593960e-02,\n",
       "        2.58574650e-01,  7.28753353e-01,  3.37600118e-01,  6.79927276e-01,\n",
       "        1.01081130e+00,  1.03474910e-01,  4.30192633e-02,  6.31305722e-01,\n",
       "        1.40914272e-01,  6.68304774e-01,  2.64473670e-01,  1.89079052e-01,\n",
       "        5.49136218e-01,  6.97330339e-01,  2.55188509e-01,  8.69211800e-02,\n",
       "        9.87472147e-01,  3.86035681e-02,  1.44754939e-01,  1.26561120e-01,\n",
       "        1.54552735e-01,  6.60185437e-01,  1.08242277e-01,  1.07788506e-01,\n",
       "        1.30225566e-01,  6.92271025e-01,  7.05445419e-01,  6.17340247e-01,\n",
       "        1.64973473e-01,  4.24607492e-01,  2.13405283e-01,  9.58271998e-01,\n",
       "        1.80851629e-01,  2.84771033e-01,  2.86552146e-01,  9.08306938e-01,\n",
       "        1.36027789e-01,  7.52904422e-02,  4.80385214e-01,  7.81923761e-01,\n",
       "        3.87393109e-01,  6.87792214e-01,  1.58890926e-01,  1.44079955e-01,\n",
       "        4.42870966e-01,  8.26131416e-01,  6.75452952e-01])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "svrLinear = LinearSVR(epsilon=0.0, \n",
    "                      tol=1e-4,\n",
    "                      C=1.0,\n",
    "                      loss='squared_epsilon_insensitive',\n",
    "                      dual=False,\n",
    "                      random_state=42,\n",
    "                      max_iter=100000) \n",
    "# entraînement \n",
    "# trainSetCleanSc = sc.fit_transform(trainSetClean)\n",
    "svrLinear.fit(trainSet,target)\n",
    "predictions = svrLinear.predict(testSet)\n",
    "print(observed)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "965eb09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nb Erreurs pour la classe LinearSVR: 179 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "nbErrors , ratio = evaluateResult(predictions)  \n",
    "print(f' nb Erreurs pour la classe {svrLinear.__class__.__name__}: {nbErrors} ({ratio:4.2f}%)') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23a1ba78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 1 0 1\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1 1 1\n",
      " 0 0 0 1 0 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1\n",
      " 0 1 1 0 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0 1 1 1 0 0 0 1 1 1]\n",
      "[0 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0\n",
      " 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 0 1 1 0 0 1 0 0 0 1 1 1 0 1\n",
      " 0 0 1 1 1 1 0 1 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1\n",
      " 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 1 0 0\n",
      " 1 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 1]\n",
      " nb Erreurs pour la classe VotingClassifier: 37 (20.67%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier , VotingClassifier\n",
    "\n",
    "votingClf = VotingClassifier( estimators = [ ('svm', svmLinear) , ('clf', sgdClf) , ('dcl',dcl)  ] ,\n",
    "                              voting='hard'\n",
    "                            )\n",
    "votingClf.fit(trainSet,target)\n",
    "predictions = votingClf.predict(testSet)\n",
    "print(observed)\n",
    "print(predictions) \n",
    "nbErrors , ratio = evaluateResult(predictions)  \n",
    "print(f' nb Erreurs pour la classe {votingClf.__class__.__name__}: {nbErrors} ({ratio:4.2f}%)') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c6541e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ca8a16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
